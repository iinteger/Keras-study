{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization(배치 정규화)\n",
    "\n",
    "* 데이터가 정규분포를 따른다고 가정하고 데이터의 평균을 0으로, 분산을 1로 만들고 약간의 노이즈를 더함.\n",
    "\n",
    "\n",
    "* 학습이 빨라지고 local optimum에 빠지는 가능성을 낮춰줌\n",
    "\n",
    "\n",
    "* 학습의 불안정화의 원인을 레이어마다 입력의 분산이 달라지는 Internal Covariance Shift(공변량 변화)로 가정하고 분산을 맞춰줌으로서 이를 해결함\n",
    "  \n",
    "  ※ [최근 논문](https://arxiv.org/pdf/1805.11604.pdf)에서는 배치 정규화의 성능 증가가 입력 분포의 안정성과는 상관이 없고, 최적화 환경을 더 smooth하게 만듦으로써 안정적인 Gradient를 유발해 빠른 Training을 가능하게 한다고 주장함\n",
    "  \n",
    "  \n",
    "* [배치 재정규화](https://arxiv.org/pdf/1702.03275.pdf) 등 기존의 배치 정규화보다 나은 성능을 보이는 기법이 발표됨\n",
    "\n",
    "\n",
    "* 일반적으로 합성곱, 전결합층 다음에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3).astype('float32')/255.\n",
    "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3).astype('float32')/255.\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\", input_shape=(32, 32, 3), activation=activations.relu))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\", activation=activations.relu))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\", activation=activations.relu))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\", activation=activations.relu))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=activations.relu))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation=activations.softmax))\n",
    "\n",
    "model.compile(loss=tensorflow.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
